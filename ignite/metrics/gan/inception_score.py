from typing import Callable, Sequence, Union

import torch
from torch import nn
from torch.nn import functional as F

from ignite.exceptions import NotComputableError
from ignite.metrics.metric import Metric, reinit__is_reduced, sync_all_reduce

__all__ = ["InceptionScore"]


class InceptionScore(Metric):
    """Calculates the inception score for synthetic images generated by a GAN model

    - ``update`` must receive output of the form ``y_pred`` or ``{'y_pred': y_pred}``.
    - `y_pred` should have the following shape (batch_size, ) and contains syntheic images created by the generator.

    Args:

        splits: (int, optional): number of splits to calculate the mean inception score.

        inception_model: (nn.Module, optional): a model used for extracting feature vectors from images.
        If not specified, :class:`~torchvision.models.inception_v3` will be used.

        output_transform: a callable that is used to transform the
            :class:`~ignite.engine.engine.Engine`'s ``process_function``'s output into the
            form expected by the metric. This can be useful if, for example, you have a multi-output model and
            you want to compute the metric with respect to one of the outputs.


        device: specifies which device updates are accumulated on. Setting the metric's
            device to be the same as your ``update`` arguments ensures the ``update`` method is non-blocking. By
            default, CPU.

    """

    def __init__(
        self,
        splits: int = 10,
        inception_model: nn.Module = None,
        output_transform: Callable = lambda x: x,
        device: Union[str, torch.device] = torch.device("cpu"),
    ):
        if inception_model is None:
            try:
                from torchvision import models

                inception_model = models.inception_v3(pretrained=True, transform_input=False)
            except ImportError:
                raise ValueError("Argument fid_model should be set")
        super(InceptionScore, self).__init__(output_transform=output_transform, device=device)
        self.inception_model = inception_model.eval().to(self._device)
        self.n_splits = splits

    @reinit__is_reduced
    def reset(self) -> None:
        self._probs = []
        self._num_examples = 0

    @reinit__is_reduced
    def update(self, output: Sequence[torch.Tensor]) -> None:
        generated = output.detach()
        inception_output = self.inception_model(generated)
        probs = F.softmax(inception_output)
        self._probs.append(probs)
        self._num_examples += output.shape[0]

    @sync_all_reduce("_probs", "_num_examples")
    def compute(self) -> float:
        if self._num_examples == 0:
            raise NotComputableError("Inception score must have at least one example before it can be computed.")

        self._probs = torch.vstack(self._probs)
        N = self._probs.shape[0]
        scores = torch.zeros((self.n_splits,), device=self._device)
        for i in range(self.n_splits):
            part = self._probs[i * (N // self.n_splits) : (i + 1) * (N // self.n_splits), :]
            kl = part * (torch.log(part) - torch.log(torch.mean(part, axis=0)))
            kl = torch.mean(torch.sum(kl, axis=1))
            scores[i] = torch.exp(kl)
        return torch.mean(scores).item()
