from typing import Callable, Sequence, Union

import torch
from torch import nn
from torch.nn import functional as F

from ignite.exceptions import NotComputableError
from ignite.metrics.metric import Metric, reinit__is_reduced, sync_all_reduce

__all__ = ["InceptionScore"]


class InceptionScore(Metric):
    """Calculates the inception score for synthetic images generated by a GAN model

    - ``update`` must receive output of the form ``y_pred`` or ``{'y_pred': y_pred}``.
    - `y_pred` should have the following shape (batch_size, ) and contains syntheic images created by the generator.

    Args:

        splits: (int, optional): number of splits to calcualte the mean inception score.

        inception_model: (nn.Module, optional): a model used for extracting feature vectors from images.
        If not specified, :class:`~torchvision.models.inception_v3` will be used.


        output_transform: a callable that is used to transform the
            :class:`~ignite.engine.engine.Engine`'s ``process_function``'s output into the
            form expected by the metric. This can be useful if, for example, you have a multi-output model and
            you want to compute the metric with respect to one of the outputs.


        device: specifies which device updates are accumulated on. Setting the metric's
            device to be the same as your ``update`` arguments ensures the ``update`` method is non-blocking. By
            default, CPU.

    """

    def __init__(
        self,
        splits: int = 10,
        inception_model: nn.Module = None,
        output_transform: Callable = lambda x: x,
        device: Union[str, torch.device] = torch.device("cpu"),
    ):
        if inception_model is None:
            try:
                from torchvision import models

                inception_model = models.inception_v3(pretrained=True, transform_input=False)
            except ImportError:
                raise ValueError("Argument fid_model should be set")
        super(InceptionScore, self).__init__(output_transform=output_transform, device=device)
        self.inception_model = inception_model.eval().to(self._device)
        self.upsample = torch.nn.Upsample(size=(299, 299), mode="bilinear")
        self.n_splits = splits

    @reinit__is_reduced
    def reset(self) -> None:
        self._inception_scores_sum = 0.0
        self._num_examples = 0

    @reinit__is_reduced
    def update(self, output: Sequence[torch.Tensor]) -> None:
        generated = output.detach()
        output = self.inception_model(self.upsample(generated))
        probs = F.softmax(output)
        split_scores = []
        N = output.shape[0]
        for k in range(self.n_splits):
            part = probs[k * (N // self.n_splits) : (k + 1) * (N // self.n_splits), :]
            py = torch.mean(part, axis=0)
            scores = []
            for i in range(part.shape[0]):
                pyx = part[i, :]
                inception_score = self._inception_score(pyx, py)
                scores.append(inception_score)

            split_scores.append(scores)

        split_scores = torch.tensor(split_scores).to(self._device)
        self._inception_scores_sum += torch.mean(split_scores).to(self._device)
        self._num_examples += 1

    @sync_all_reduce("_inception_scores_sum", "_num_examples")
    def compute(self) -> float:
        if self._num_examples == 0:
            raise NotComputableError("Inception score must have at least one example before it can be computed.")
        return self._inception_scores_sum / self._num_examples

    def _inception_score(self, pyx, py, eps=1e-15):
        kl_div = pyx * (torch.log(pyx + eps) - torch.log(py + eps))
        avg_kl_div = torch.mean(kl_div.sum())
        inception_score = torch.exp(avg_kl_div)
        return inception_score
